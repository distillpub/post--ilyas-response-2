<!doctype html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <script src="https://distill.pub/template.v2.js"></script>
  <style><%= require("raw-loader!../static/style.css") %></style>
</head>

<body>

<d-front-matter>
  <script type="text/json">{
  "title": "Robust feature leakage in adverserial examples",
  "description": "An example project using webpack and svelte-loader and ejs to inline SVGs",
  "password": "svgs",
  "authors": [
    {
      "author": "Ludwig Schubert",
      "authorURL": "https://schubert.io/",
      "affiliation": "Google Brain Team",
      "affiliationURL": "https://g.co/brain"
    }
  ],
  "katex": {
    "delimiters": [
      {
        "left": "$",
        "right": "$",
        "display": false
      },
      {
        "left": "$$",
        "right": "$$",
        "display": true
      }
    ]
  }
  }</script>
</d-front-matter>

<d-title></d-title>

<d-article>

  <p>
Ilya' et al's heuristics for disentangling robust and non-robust features have the potential to signal a dramatic change in our understanding of adverserial examples; thus it is important for us to take stock of how well these constructions work based on their own stated goals. 
  </p>

  <p>
In this manuscript, we attempt to quantify the degree of leakage of robust features in the non-robust datasets, generated from adverserial examples. 
  </p>

  <p>
Our method for lower bounding feature leakage consists of the following two steps:

<ul>
  <li>First, we construct hand-crafted features $f_i$ that are provabily robust on the training dataset on an $\epsilon=0.25$ $l_2$ adversary. (Footnote: We are operating under the assumption, based on a reading of Equation 5 in Ilyas. et.al, that all the features come from a certifiabily robust model are robust.)</li>
  <li>Next, we train a linear model on these features on `d_det` and `d_rand`, and evaluate its accuracy.</li>
</ul>
  </p>

  <p>
Since we are training the non-robust dataset entirely on robust features, this we expect there to the correlation to be close to $0$ in the case of `d_rand` and negative in the case of `d_non-robust`. Thus, if the construction is work, we would expect accuracy from the models constructed in the manner shown above.
  </p>

  <p>
The results of this construction are summarized in the following table:
  </p>

  <p>
In summary, we find evidence for feature leakage that is sufficient to explain up to [1/8]th of the accuracy on the final model. It is possible, with stronger and more robust features, this number may be higher. We have found, however, no evidence of leakage in the `d_det` constructions. 
  </p> 

</d-article>



<d-appendix>
  <h3>Acknowledgments</h3>
  <p>
    We are deeply grateful to...
  </p>

  <p>
    Many of our diagrams are based on...
  </p>

  <h3>Author Contributions</h3>
  <p>
    <b>Research:</b> Alex developed ...
  </p>

  <p>
    <b>Writing & Diagrams:</b> The text was initially drafted by...
  </p>


  <d-footnote-list></d-footnote-list>
  <d-citation-list></d-citation-list>
</d-appendix>

<!-- bibliography will be inlined during Distill pipeline's pre-rendering -->
<d-bibliography src="bibliography.bib"></d-bibliography>

</body>
